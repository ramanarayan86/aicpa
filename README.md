AICPA: AI Code Performance Analyzer

A modular, AI-agent-powered system to analyze, benchmark, and optimize PyTorch/C++ ML code across NVIDIA GPUs using Torch Profiler, TorchInductor, and CUDA tools.

## ðŸ§± Directory Structure

```
aicpa/
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ language_detector.py
â”‚   â”œâ”€â”€ static_graph_parser.py
â”‚   â”œâ”€â”€ profiler_agent.py
â”‚   â”œâ”€â”€ efficiency_estimator.py
â”‚   â”œâ”€â”€ bottleneck_detector.py
â”‚   â”œâ”€â”€ optimization_agent.py
â”‚   â””â”€â”€ explain_agent.py
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ hardware_info.py
â”‚   â”œâ”€â”€ runner.py
â”‚   â””â”€â”€ utils.py
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ test_model.py
â”‚   â””â”€â”€ custom_loader.py
â”œâ”€â”€ ui/
â”‚   â”œâ”€â”€ app.py  # Streamlit or Gradio
â”‚   â””â”€â”€ dashboard.py
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ logs/
â”‚   â””â”€â”€ reports/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ run_pipeline.py
â”‚   â””â”€â”€ benchmark_cli.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```


## ðŸš€ Key Features

- ðŸ” Deep runtime and static profiling
- âš™ï¸ Hardware-aware FLOPs and memory analysis
- ðŸ“ˆ Op-by-op efficiency vs peak comparison
- ðŸ§  AI Agents for optimization recommendations
- ðŸ§ª Support for PyTorch, TorchInductor, TorchScript, and C++

## ðŸ“¦ To-Do

- [ ] Implement full pipeline
- [ ] Add Triton optimization support
- [ ] Deploy Streamlit frontend
- [ ] Add real ML model benchmarking

---

## ðŸ“œ Sample `requirements.txt`

```txt
torch>=2.1
pynvml
torchvision
pandas
numpy
streamlit
plotly

